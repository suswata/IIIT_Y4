{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "invalid-saudi",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.021939,
     "end_time": "2022-07-11T09:42:10.370150",
     "exception": false,
     "start_time": "2022-07-11T09:42:10.348211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Market Basket Analysis using PySpark's Implementation of FPGrowth\n",
    "\n",
    "FPGrowth is an algorithm that performs market basket analysis, similar to the Apriori algorithm. I first used it when I ran into resource issues with Apriori and I was impressed with the speed. So I am giving it a try on this dataset using pyspark. The [documentation for FPGrowth](https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html) is pretty straightforward and describes the hyperparameters and the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interim-tennis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:42:10.425949Z",
     "iopub.status.busy": "2022-07-11T09:42:10.422324Z",
     "iopub.status.idle": "2022-07-11T09:42:10.437845Z",
     "shell.execute_reply": "2022-07-11T09:42:10.436898Z",
     "shell.execute_reply.started": "2022-07-11T09:24:37.565080Z"
    },
    "papermill": {
     "duration": 0.046103,
     "end_time": "2022-07-11T09:42:10.438080",
     "exception": false,
     "start_time": "2022-07-11T09:42:10.391977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/groceries-dataset-for-market-basket-analysismba/Groceries data.csv\n",
      "/kaggle/input/groceries-dataset-for-market-basket-analysismba/basket.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exclusive-deficit",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-07-11T09:42:10.485788Z",
     "iopub.status.busy": "2022-07-11T09:42:10.485106Z",
     "iopub.status.idle": "2022-07-11T09:43:11.241657Z",
     "shell.execute_reply": "2022-07-11T09:43:11.240078Z",
     "shell.execute_reply.started": "2022-07-11T09:24:37.583860Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 60.781389,
     "end_time": "2022-07-11T09:43:11.241868",
     "exception": false,
     "start_time": "2022-07-11T09:42:10.460479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 281.3 MB 28 kB/s \r\n",
      "\u001b[?25hCollecting py4j==0.10.9.5\r\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 199 kB 58.7 MB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=934e11b6078a967e804742fcc2c802b246eaa61aad503650dfd6eccffc35817a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\r\n",
      "Collecting pyspark_dist_explore\r\n",
      "  Downloading pyspark_dist_explore-0.1.8-py3-none-any.whl (7.2 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pyspark_dist_explore) (1.19.5)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from pyspark_dist_explore) (3.4.1)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from pyspark_dist_explore) (1.2.3)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from pyspark_dist_explore) (1.5.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pyspark_dist_explore) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pyspark_dist_explore) (2.8.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pyspark_dist_explore) (1.3.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pyspark_dist_explore) (7.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pyspark_dist_explore) (0.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->pyspark_dist_explore) (1.15.0)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pyspark_dist_explore) (2021.1)\r\n",
      "Installing collected packages: pyspark-dist-explore\r\n",
      "Successfully installed pyspark-dist-explore-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install pyspark_dist_explore # Used for a histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-sector",
   "metadata": {
    "papermill": {
     "duration": 0.177692,
     "end_time": "2022-07-11T09:43:11.595889",
     "exception": false,
     "start_time": "2022-07-11T09:43:11.418197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import the relevant libraries\n",
    "\n",
    "The libraries such as SparkContext and SparkSession are general pyspark libraries needed for pyspark applications. The specific function used for market basket analysis is [FPGrowth](https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extensive-simon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:11.984297Z",
     "iopub.status.busy": "2022-07-11T09:43:11.983015Z",
     "iopub.status.idle": "2022-07-11T09:43:12.734016Z",
     "shell.execute_reply": "2022-07-11T09:43:12.734545Z",
     "shell.execute_reply.started": "2022-07-11T09:30:51.991839Z"
    },
    "papermill": {
     "duration": 0.96355,
     "end_time": "2022-07-11T09:43:12.734780",
     "exception": false,
     "start_time": "2022-07-11T09:43:11.771230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "# Rather than generally using the functions, I should explicitly import the ones I want.\n",
    "from pyspark.sql import functions as f, SparkSession, Column\n",
    "from pyspark_dist_explore import hist\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-green",
   "metadata": {
    "papermill": {
     "duration": 0.173833,
     "end_time": "2022-07-11T09:43:13.083451",
     "exception": false,
     "start_time": "2022-07-11T09:43:12.909618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create a spark session \n",
    "\n",
    "More info on [SparkSession.builder](https://spark.apache.org/docs/latest/sql-getting-started.html) for specific settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driving-shirt",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:13.428082Z",
     "iopub.status.busy": "2022-07-11T09:43:13.426965Z",
     "iopub.status.idle": "2022-07-11T09:43:20.692389Z",
     "shell.execute_reply": "2022-07-11T09:43:20.691383Z",
     "shell.execute_reply.started": "2022-07-11T09:30:57.225296Z"
    },
    "papermill": {
     "duration": 7.439415,
     "end_time": "2022-07-11T09:43:20.692621",
     "exception": false,
     "start_time": "2022-07-11T09:43:13.253206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a spark session. All sorts of settings can be specified here. \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"arlUsingPyspark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-weather",
   "metadata": {
    "papermill": {
     "duration": 0.169504,
     "end_time": "2022-07-11T09:43:21.035675",
     "exception": false,
     "start_time": "2022-07-11T09:43:20.866171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read in the data \n",
    "\n",
    "I didn't end up using the ID number of the customer, but one thing that is important to know about pyspark dataframes is that they do not preserve order once they are sliced and diced. This dataset relies on the order of the two dataframes from the csv files having their order preserved, because the basket does not contain the customer ID number. Since I didn't need the customer ID number, I assigned a monotonically increasing ID number to each row as the file is read in. \n",
    "\n",
    "This monotonically increasing ID number is not sequential, so it cannot be used directly to match the rows of the two dataframes. If I had needed the customer ID number to be associated with the basket, I would have had to use a window function over the ID number to create an index, and then match on the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unique-dover",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:21.382337Z",
     "iopub.status.busy": "2022-07-11T09:43:21.381608Z",
     "iopub.status.idle": "2022-07-11T09:43:29.247425Z",
     "shell.execute_reply": "2022-07-11T09:43:29.246182Z",
     "shell.execute_reply.started": "2022-07-11T09:31:04.745072Z"
    },
    "papermill": {
     "duration": 8.0415,
     "end_time": "2022-07-11T09:43:29.247707",
     "exception": false,
     "start_time": "2022-07-11T09:43:21.206207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/kaggle/input/groceries-dataset-for-market-basket-analysismba/basket.csv\", header=True).withColumn(\"id\", f.monotonically_increasing_id())\n",
    "df_all = spark.read.csv(\"/kaggle/input/groceries-dataset-for-market-basket-analysismba/Groceries data.csv\", header=True).withColumn(\"id\", f.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "junior-chicago",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:29.602420Z",
     "iopub.status.busy": "2022-07-11T09:43:29.601665Z",
     "iopub.status.idle": "2022-07-11T09:43:30.467227Z",
     "shell.execute_reply": "2022-07-11T09:43:30.466330Z",
     "shell.execute_reply.started": "2022-07-11T09:31:32.625100Z"
    },
    "papermill": {
     "duration": 1.041381,
     "end_time": "2022-07-11T09:43:30.467483",
     "exception": false,
     "start_time": "2022-07-11T09:43:29.426102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-------------------+------+----+----+----+----+----+----+----+---+\n",
      "|          0|                 1|                  2|     3|   4|   5|   6|   7|   8|   9|  10| id|\n",
      "+-----------+------------------+-------------------+------+----+----+----+----+----+----+----+---+\n",
      "| whole milk|            pastry|        salty snack|  null|null|null|null|null|null|null|null|  0|\n",
      "|    sausage|        whole milk|semi-finished bread|yogurt|null|null|null|null|null|null|null|  1|\n",
      "|       soda|pickled vegetables|               null|  null|null|null|null|null|null|null|null|  2|\n",
      "|canned beer|   misc. beverages|               null|  null|null|null|null|null|null|null|null|  3|\n",
      "|    sausage|  hygiene articles|               null|  null|null|null|null|null|null|null|null|  4|\n",
      "+-----------+------------------+-------------------+------+----+----+----+----+----+----+----+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------+----------+----------------+----+-----+---+-----------+---+\n",
      "|Member_number|      Date| itemDescription|year|month|day|day_of_week| id|\n",
      "+-------------+----------+----------------+----+-----+---+-----------+---+\n",
      "|         1808|2015-07-21|  tropical fruit|2015|    7| 21|          1|  0|\n",
      "|         2552|2015-05-01|      whole milk|2015|    5|  1|          4|  1|\n",
      "|         2300|2015-09-19|       pip fruit|2015|    9| 19|          5|  2|\n",
      "|         1187|2015-12-12|other vegetables|2015|   12| 12|          5|  3|\n",
      "|         3037|2015-01-02|      whole milk|2015|    1|  2|          4|  4|\n",
      "+-------------+----------+----------------+----+-----+---+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show is pyspark's version of head(), although it can be slow so I do try to skip this. \n",
    "df.show(5)\n",
    "df_all.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-liberal",
   "metadata": {
    "papermill": {
     "duration": 0.17125,
     "end_time": "2022-07-11T09:43:30.885562",
     "exception": false,
     "start_time": "2022-07-11T09:43:30.714312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## printSchema() shows the structure of the Spark dataframe\n",
    "\n",
    "This is a really useful debugging tool and one of the first things I look at when I get into trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "yellow-halloween",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:31.240128Z",
     "iopub.status.busy": "2022-07-11T09:43:31.239354Z",
     "iopub.status.idle": "2022-07-11T09:43:31.255982Z",
     "shell.execute_reply": "2022-07-11T09:43:31.256933Z",
     "shell.execute_reply.started": "2022-07-11T09:31:50.269610Z"
    },
    "papermill": {
     "duration": 0.195898,
     "end_time": "2022-07-11T09:43:31.257245",
     "exception": false,
     "start_time": "2022-07-11T09:43:31.061347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: string (nullable = true)\n",
      " |-- 1: string (nullable = true)\n",
      " |-- 2: string (nullable = true)\n",
      " |-- 3: string (nullable = true)\n",
      " |-- 4: string (nullable = true)\n",
      " |-- 5: string (nullable = true)\n",
      " |-- 6: string (nullable = true)\n",
      " |-- 7: string (nullable = true)\n",
      " |-- 8: string (nullable = true)\n",
      " |-- 9: string (nullable = true)\n",
      " |-- 10: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n",
      "root\n",
      " |-- Member_number: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- itemDescription: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printSchema() shows the structure of the dataframe. This is important for debugging.\n",
    "df.printSchema()\n",
    "df_all.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-siemens",
   "metadata": {
    "papermill": {
     "duration": 0.174239,
     "end_time": "2022-07-11T09:43:31.605575",
     "exception": false,
     "start_time": "2022-07-11T09:43:31.431336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How many baskets are there per customer? \n",
    "\n",
    "I wanted to look at the number of baskets each customer had in the dataset. This can tell you if your dataset is appropriate for market basket analysis. They have to have baskets or there will be no data to match on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "challenging-sandwich",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:31.965824Z",
     "iopub.status.busy": "2022-07-11T09:43:31.964755Z",
     "iopub.status.idle": "2022-07-11T09:43:33.883742Z",
     "shell.execute_reply": "2022-07-11T09:43:33.882703Z",
     "shell.execute_reply.started": "2022-07-11T09:33:12.865891Z"
    },
    "papermill": {
     "duration": 2.108782,
     "end_time": "2022-07-11T09:43:33.883989",
     "exception": false,
     "start_time": "2022-07-11T09:43:31.775207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|Member_number|count|\n",
      "+-------------+-----+\n",
      "|         2904|   10|\n",
      "|         3959|   14|\n",
      "|         2294|   23|\n",
      "|         4032|    4|\n",
      "|         1512|   10|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_baskets = df_all.groupBy(\"Member_number\").count()\n",
    "num_baskets.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-premiere",
   "metadata": {
    "papermill": {
     "duration": 0.191814,
     "end_time": "2022-07-11T09:43:34.358828",
     "exception": false,
     "start_time": "2022-07-11T09:43:34.167014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The distribution of the number of baskets\n",
    "\n",
    "Create a histogram of the number of baskets using pyspark_dist_explore. This library can create some fast visualizations on a pyspark dataframe, similar to matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "embedded-reply",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:34.710350Z",
     "iopub.status.busy": "2022-07-11T09:43:34.709194Z",
     "iopub.status.idle": "2022-07-11T09:43:37.053171Z",
     "shell.execute_reply": "2022-07-11T09:43:37.052041Z",
     "shell.execute_reply.started": "2021-07-04T09:52:50.195785Z"
    },
    "papermill": {
     "duration": 2.51904,
     "end_time": "2022-07-11T09:43:37.053373",
     "exception": false,
     "start_time": "2022-07-11T09:43:34.534333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([302., 328., 178., 371., 237., 341., 251., 538., 252., 192., 179.,\n",
       "        144., 136., 109.,  69., 110.,  49.,  23.,  29.,  14.,  11.,   9.,\n",
       "         13.,   4.,   1.,   4.,   0.,   3.,   0.,   1.]),\n",
       " array([ 2.        ,  3.13333333,  4.26666667,  5.4       ,  6.53333333,\n",
       "         7.66666667,  8.8       ,  9.93333333, 11.06666667, 12.2       ,\n",
       "        13.33333333, 14.46666667, 15.6       , 16.73333333, 17.86666667,\n",
       "        19.        , 20.13333333, 21.26666667, 22.4       , 23.53333333,\n",
       "        24.66666667, 25.8       , 26.93333333, 28.06666667, 29.2       ,\n",
       "        30.33333333, 31.46666667, 32.6       , 33.73333333, 34.86666667,\n",
       "        36.        ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "hist(ax, num_baskets.select('count'), bins = 30, color=['blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-neighborhood",
   "metadata": {
    "papermill": {
     "duration": 0.176517,
     "end_time": "2022-07-11T09:43:37.424663",
     "exception": false,
     "start_time": "2022-07-11T09:43:37.248146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run PySpark's implementation of FPGrowth\n",
    "\n",
    "First step is to collect the baskets into sets. FPGrowth requires each basket to be an array that looks like:\n",
    "\n",
    "* ['item1','item2', 'imem3']\n",
    "\n",
    "The basket dataframe uses wide rather than long format, with Null if the basket contains fewer than 10 items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "celtic-uganda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:37.771272Z",
     "iopub.status.busy": "2022-07-11T09:43:37.770543Z",
     "iopub.status.idle": "2022-07-11T09:43:38.059511Z",
     "shell.execute_reply": "2022-07-11T09:43:38.058553Z",
     "shell.execute_reply.started": "2022-07-11T09:35:03.693634Z"
    },
    "papermill": {
     "duration": 0.465601,
     "end_time": "2022-07-11T09:43:38.059790",
     "exception": false,
     "start_time": "2022-07-11T09:43:37.594189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- basket: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+---+--------------------------------------------------------------------------------------------+\n",
      "|id |basket                                                                                      |\n",
      "+---+--------------------------------------------------------------------------------------------+\n",
      "|0  |[whole milk, pastry, salty snack, null, null, null, null, null, null, null, null]           |\n",
      "|1  |[sausage, whole milk, semi-finished bread, yogurt, null, null, null, null, null, null, null]|\n",
      "|2  |[soda, pickled vegetables, null, null, null, null, null, null, null, null, null]            |\n",
      "+---+--------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_basket = df.select(\"id\", f.array([df[c] for c in df.columns[:11]]).alias(\"basket\"))\n",
    "df_basket.printSchema()\n",
    "# False tells show() to not truncate the columns when printing.\n",
    "df_basket.show(3, False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-importance",
   "metadata": {
    "papermill": {
     "duration": 0.17694,
     "end_time": "2022-07-11T09:43:38.479650",
     "exception": false,
     "start_time": "2022-07-11T09:43:38.302710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### There should not be any nulls in the array. Remove using array_except()\n",
    "\n",
    "This will be the final dataframe used for FPGrowth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "under-reminder",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:38.882050Z",
     "iopub.status.busy": "2022-07-11T09:43:38.881279Z",
     "iopub.status.idle": "2022-07-11T09:43:39.220453Z",
     "shell.execute_reply": "2022-07-11T09:43:39.219408Z",
     "shell.execute_reply.started": "2022-07-11T09:35:30.588071Z"
    },
    "papermill": {
     "duration": 0.521651,
     "end_time": "2022-07-11T09:43:39.220703",
     "exception": false,
     "start_time": "2022-07-11T09:43:38.699052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------+\n",
      "|id |basket                                            |\n",
      "+---+--------------------------------------------------+\n",
      "|0  |[whole milk, pastry, salty snack]                 |\n",
      "|1  |[sausage, whole milk, semi-finished bread, yogurt]|\n",
      "|2  |[soda, pickled vegetables]                        |\n",
      "+---+--------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_aggregated = df_basket.select(\"id\", f.array_except(\"basket\", f.array(f.lit(None))).alias(\"basket\"))\n",
    "df_aggregated.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-antique",
   "metadata": {
    "papermill": {
     "duration": 0.167719,
     "end_time": "2022-07-11T09:43:39.585152",
     "exception": false,
     "start_time": "2022-07-11T09:43:39.417433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "The hyperparameters used in FPGrowth are minimum support, minimum confidence, and number of partitions. \n",
    "\n",
    "* minSupport - The minimum support of an item to be considered in a frequent itemset. \n",
    "* minConfidence - The minimum confidence for generating an association rule from an itemset. \n",
    "* numPartitions - The number of partitions used to distribute the work. This is Spark-specific. \n",
    "\n",
    "The default number of partitions is the number of partitions for the input dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "floating-stress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:39.929317Z",
     "iopub.status.busy": "2022-07-11T09:43:39.928224Z",
     "iopub.status.idle": "2022-07-11T09:43:41.351467Z",
     "shell.execute_reply": "2022-07-11T09:43:41.353201Z",
     "shell.execute_reply.started": "2022-07-11T09:35:46.589762Z"
    },
    "papermill": {
     "duration": 1.600979,
     "end_time": "2022-07-11T09:43:41.353520",
     "exception": false,
     "start_time": "2022-07-11T09:43:39.752541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run FPGrowth and fit the model.\n",
    "fp = FPGrowth(minSupport=0.001, minConfidence=0.001, itemsCol='basket', predictionCol='prediction')\n",
    "model = fp.fit(df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "curious-summer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:41.708175Z",
     "iopub.status.busy": "2022-07-11T09:43:41.706028Z",
     "iopub.status.idle": "2022-07-11T09:43:43.268389Z",
     "shell.execute_reply": "2022-07-11T09:43:43.267644Z",
     "shell.execute_reply.started": "2022-07-11T09:35:50.527409Z"
    },
    "papermill": {
     "duration": 1.735533,
     "end_time": "2022-07-11T09:43:43.268545",
     "exception": false,
     "start_time": "2022-07-11T09:43:41.533012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----+\n",
      "|items                   |freq|\n",
      "+------------------------+----+\n",
      "|[cocoa drinks]          |16  |\n",
      "|[canned fruit]          |21  |\n",
      "|[specialty cheese]      |72  |\n",
      "|[chocolate marshmallow] |60  |\n",
      "|[pet care]              |85  |\n",
      "|[house keeping products]|45  |\n",
      "|[jam]                   |34  |\n",
      "|[light bulbs]           |29  |\n",
      "|[beef]                  |508 |\n",
      "|[beef, frankfurter]     |15  |\n",
      "+------------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View a subset of the frequent itemset. \n",
    "model.freqItemsets.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "closing-organization",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:43.814036Z",
     "iopub.status.busy": "2022-07-11T09:43:43.812968Z",
     "iopub.status.idle": "2022-07-11T09:43:44.889923Z",
     "shell.execute_reply": "2022-07-11T09:43:44.888918Z",
     "shell.execute_reply.started": "2022-07-11T09:40:14.888228Z"
    },
    "papermill": {
     "duration": 1.349187,
     "end_time": "2022-07-11T09:43:44.890107",
     "exception": false,
     "start_time": "2022-07-11T09:43:43.540920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------+-------------------+------------------+---------------------+\n",
      "|antecedent           |consequent  |confidence         |lift              |support              |\n",
      "+---------------------+------------+-------------------+------------------+---------------------+\n",
      "|[bottled beer]       |[whole milk]|0.15781710914454278|0.9993302598941151|0.007150972398583172 |\n",
      "|[detergent]          |[whole milk]|0.16279069767441862|1.030824041177455 |0.001403461872619127 |\n",
      "|[semi-finished bread]|[whole milk]|0.176056338028169  |1.1148247930239072|0.001670787943594199 |\n",
      "|[sausage, rolls/buns]|[whole milk]|0.2125             |1.345593525179856 |0.0011361358016440553|\n",
      "|[sausage, soda]      |[whole milk]|0.1797752808988764 |1.1383739010113787|0.0010693042839002875|\n",
      "|[ham]                |[whole milk]|0.16015625         |1.0141421789039358|0.0027400922274944863|\n",
      "|[frozen fish]        |[whole milk]|0.1568627450980392 |0.9932870312746344|0.0010693042839002875|\n",
      "|[sausage, whole milk]|[yogurt]    |0.16417910447761194|1.9117602648237413|0.0014702933903628951|\n",
      "|[sausage, yogurt]    |[whole milk]|0.2558139534883721 |1.6198663504217148|0.0014702933903628951|\n",
      "|[yogurt, rolls/buns] |[whole milk]|0.17094017094017094|1.0824281751069733|0.0013366303548753592|\n",
      "+---------------------+------------+-------------------+------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use filter to view just the association rules with the highest confidence.\n",
    "model.associationRules.filter(model.associationRules.confidence>0.15).show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-darwin",
   "metadata": {
    "papermill": {
     "duration": 0.173733,
     "end_time": "2022-07-11T09:43:45.249247",
     "exception": false,
     "start_time": "2022-07-11T09:43:45.075514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Let's create a prediction based on the generated association rules\n",
    "\n",
    "This is pretty similar to creating a prediction using other methods. The data column needs to have the same column name as the column specified in the model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "excessive-horizon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:45.605778Z",
     "iopub.status.busy": "2022-07-11T09:43:45.604965Z",
     "iopub.status.idle": "2022-07-11T09:43:46.130285Z",
     "shell.execute_reply": "2022-07-11T09:43:46.129316Z",
     "shell.execute_reply.started": "2022-07-11T09:40:27.782158Z"
    },
    "papermill": {
     "duration": 0.702297,
     "end_time": "2022-07-11T09:43:46.130513",
     "exception": false,
     "start_time": "2022-07-11T09:43:45.428216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- basket: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+-----------------------------+\n",
      "|basket                       |\n",
      "+-----------------------------+\n",
      "|[ham, yogurt, light bulbs]   |\n",
      "|[jam, cocoa drinks, pet care]|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a PySpark dataframe\n",
    "columns = ['basket']\n",
    "new_data = [(['ham', 'yogurt', 'light bulbs'],), (['jam', 'cocoa drinks', 'pet care'],)]\n",
    "rdd = spark.sparkContext.parallelize(new_data)\n",
    "new_df = rdd.toDF(columns)\n",
    "new_df.printSchema()\n",
    "new_df.show(2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-treaty",
   "metadata": {
    "papermill": {
     "duration": 0.170707,
     "end_time": "2022-07-11T09:43:46.476281",
     "exception": false,
     "start_time": "2022-07-11T09:43:46.305574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict!\n",
    "\n",
    "Now that we have a new PySpark dataframe with data, predict. The first basket generates numerous predictions based on the association rules, however the second basket does not generate any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "specialized-medicine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T09:43:46.819525Z",
     "iopub.status.busy": "2022-07-11T09:43:46.818374Z",
     "iopub.status.idle": "2022-07-11T09:43:47.507518Z",
     "shell.execute_reply": "2022-07-11T09:43:47.506530Z",
     "shell.execute_reply.started": "2022-07-11T09:40:41.797492Z"
    },
    "papermill": {
     "duration": 0.863093,
     "end_time": "2022-07-11T09:43:47.507757",
     "exception": false,
     "start_time": "2022-07-11T09:43:46.644664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|basket                       |prediction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+-----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[ham, yogurt, light bulbs]   |[beef, oil, detergent, chocolate, candy, berries, frankfurter, sausage, coffee, pip fruit, white bread, salty snack, domestic eggs, root vegetables, bottled beer, specialty bar, long life bakery product, rolls/buns, other vegetables, soda, whole milk, canned beer, fruit/vegetable juice, dessert, newspapers, bottled water, margarine, hamburger meat, pastry, onions, pork, chicken, herbs, soft cheese, frozen meals, frozen vegetables, UHT-milk, brown bread, citrus fruit, butter, misc. beverages, chewing gum, shopping bags, cream cheese , waffles, whipped/sour cream, butter milk, hard cheese, napkins, curd, tropical fruit]|\n",
      "|[jam, cocoa drinks, pet care]|[]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "+-----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(new_df).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-palace",
   "metadata": {
    "papermill": {
     "duration": 0.172155,
     "end_time": "2022-07-11T09:43:47.852077",
     "exception": false,
     "start_time": "2022-07-11T09:43:47.679922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 109.119384,
   "end_time": "2022-07-11T09:43:50.051935",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-11T09:42:00.932551",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
